# 1.2 Use Cases 使用案例
下面是对Apache Kafka的一些常用用例的描述。有关这些领域的概述，请[参阅本文](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying).

## Messaging 消息

Kafka可以很好地替代传统消息代理。 使用消息代理有多种原因（从数据产生器中解耦处理，缓冲未处理的消息，等等）。 与大多数消息代理系统相比，Kafka具有更好的吞吐量，内置的分区，复制和容错能力，这使其成为大规模消息代理应用程序的理想解决方案。

根据我们的经验，消息传递的使用通常吞吐量较低，但是可能需要较低的端到端延迟，而这通常取决于Kafka提供的强大的持久性保证。

在此领域中，Kafka与ActiveMQ或RabbitMQ等传统消息传递系统相当。

## Website Activity Tracking 网站活动跟踪
Kafka最初的用例是能够将用户活动跟踪管道重建为一组实时发布-订阅feed。这意味着将站点活动(页面视图、搜索或用户可能采取的其他操作)发布到中心主题，每个活动类型有一个主题。这些提要可用于订阅一系列用例，包括实时处理、实时监视和加载到Hadoop或离线数据仓库系统以进行离线处理和报告。

活动跟踪通常非常频繁，因为每个用户页面视图都会生成许多活动消息。

## Metrics 指标
Kafka通常用于操作监控数据。这涉及聚合来自分布式应用程序的统计信息，以生成操作数据的集中提要。

## Log Aggregation 日志聚合
许多人使用Kafka代替日志聚合解决方案。 日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（也许是文件服务器或HDFS）以进行处理。 Kafka提取文件的详细信息，并以日志流的形式更清晰地抽象日志或事件数据。 这允许较低延迟的处理，并更容易支持多个数据源和分布式数据消耗。 与Scribe或Flume等以日志为中心的系统相比，Kafka具有同样出色的性能，由于复制而提供的更强的耐用性保证以及更低的端到端延迟。

## Stream Processing 信息流处理
Kafka的许多用户在由多个阶段组成的处理管道中处理数据，其中原始输入数据从Kafka主题中使用，然后进行汇总，充实或以其他方式转换为新主题，以供进一步使用或后续处理。 例如，用于推荐新闻文章的处理管道可能会从RSS提要中检索文章内容，并将其发布到“文章”主题中。 进一步的处理可能会对该内容进行规范化或重复数据删除，并将清洗后的文章内容发布到新主题中； 最后的处理阶段可能会尝试将此内容推荐给用户。 这样的处理管道基于各个主题创建实时数据流图。 从0.10.0.0开始，Apache Kafka中提供了一个轻量但功能强大的流处理库，称为Kafka Streams，可以执行上述数据处理。 除了Kafka Streams，其他开源流处理工具还包括Apache Storm和Apache Samza。

## Event Sourcing 事件源驱动
事件源是一种应用程序设计样式，其中状态更改以时间顺序记录记录。 Kafka对大量存储的日志数据的支持使其成为以这种样式构建的应用程序的绝佳后端。

## Commit Log 提交日志
Kafka可以用作一种分布式系统的外部提交日志。 该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。 Kafka中的日志压缩功能有助于支持此用法。 在这种用法中，Kafka与Apache BookKeeper项目类似。

