# 1.1 介绍
Apache Kafka 是一个分布式流平台.这是什么意思呢?

流媒体平台有三个关键功能:
+ 发布和订阅记录流，类似于消息队列或企业消息传递系统.
+ 以容错的持久方式存储记录流
+ 在记录发生时处理记录流

Kafka通常用于两大类应用程序:
+ 构建实时流数据管道，在系统或应用程序之间可靠地获取数据
+ 构建转换或响应数据流的实时流应用程序

为了理解Kafka是如何做这些事情的，让我们深入探索一下Kafka的自底向上的能力。

首先是一些概念:
+ Kafka作为一个集群在一个或多个服务器上运行，这些服务器可以跨越多个数据中心。
+ Kafka集群将记录流存储在称为topic(主题)的类别中。
+ 每个记录由一个键、一个值和一个时间戳组成。

Kafka有5个核心api:
+ Producer API 允许应用程序将记录流发布到一个或多个Kafka topics.
+ Consumer API 允许应用程序订阅一个或多个topics并处理产生给它们的记录流。
+ Streams API 允许应用程序充当流处理器，使用来自一个或多个topics的输入流，并将输出流生成到一个或多个输出topics，从而有效地将输入流转换为输出流。
+ Connector API 允许构建和运行将Kafka topics 连接到现有应用程序或数据系统的可重用生产者或消费者。例如，到关系数据库的连接器可能会捕获对表的每个更改。
+ Admin API 允许管理和检查topics、代理和其他Kafka对象。
如图所示:
[kafka-apis]("/resource/kafka-apis.png")

在Kafka中，客户端和服务器之间的通信是通过一个简单的、高性能的、与语言无关的`[TCP协议](https://kafka.apache.org/protocol.html)`完成的。该协议进行版本控制，并保持与旧版本的向后兼容性。我们为Kafka提供了一个Java客户端，但是客户端有很多
[语言版本](https://cwiki.apache.org/confluence/display/KAFKA/Clients).

## Topics and Logs
首先,让我们深入探讨Kafka提供的记录topic的核心抽象.

topic是将记录发布到的类别或订阅源名称。 Kafka中的主题始终是多用户的. 也就是说，一个主题可以有零个，一个或多个消费者来订阅写入该主题的数据。

对于每个topic，Kafka集群维护一个分区日志，如下所示:
[kafka-apis]("/resource/log_anatomy.png")
每个分区(partition)都是一个有序的、不可变的记录序列，不断地追加到一个结构化提交日志中。分区中的每个记录都分配了一个连续的id号，称为`偏移量`，它唯一地标识分区中的每个记录。

Kafka群集使用`可配置的保留期限`持久地保留所有已发布的记录（无论是否已使用它们。例如，如果将保留策略设置为两天，则在发布记录后的两天内，该记录可供使用，之后将被丢弃以释放空间。`Kafka的性能相对于数据大小实际上是恒定的`，因此长时间存储数据不是问题。
[kafka-apis]("/resource/log_consumer.png")

实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的`偏移量或位置`。 此偏移量由使用者控制：通常，使用者在读取记录时会线性地推进其偏移量，但是实际上，由于位置是由使用者控制的，因此它可以按喜欢的任何顺序使用记录。 例如，使用者可以重置到较旧的偏移量以重新处理过去的数据，或者跳到最近的记录并从“现在”开始使用。

这些功能的组合意味着Kafka的消费者非常方便-他们来来去去对集群或其他消费者没有太大影响.例如，您可以使用我们的命令行工具来定位到任何topic“尾部”，而无需更改任何现有使用者所消耗的内容。

日志中的分区有多种用途。首先，它们允许日志扩展到超出单个服务器所能容纳的大小。 每个单独的分区都必须适合托管它的服务器，但是一个主题可能有很多分区，因此它可以处理任意数量的数据。 其次，它们充当并行性的单元-稍有更多。

## Distribution 分布式
日志的分区分布在Kafka群集中的服务器上，每个服务器`处理数据`并要求`共享分区`。 每个分区都在`可配置数量`的服务器之间`复制`，以实现容错功能。

每个分区都有一个充当“领导者”的服务器和零个或多个充当“跟随者”的服务器。 领导者处理对分区的所有读写请求，而跟随者则被动地复制领导者。 如果领导者失败，则跟随者之一将自动成为新领导者。 每个服务器充当其某些分区的领导者，而充当其他分区的跟随者，因此群集中的负载得到了很好的平衡。

## Geo-Replication 异地备份
`Kafka MirrorMaker`为您的集群提供异地备份支持。 使用`MirrorMaker`，可以在多个数据中心或云区域之间复制消息。您可以在主动/被动方案中使用它进行备份和恢复数据。 或在主动/主动方案中将数据放置在离您的用户更近的位置，支持数据放置位置变更需求。

## Producers 生产者
生产者将数据发布到他们选择的主题。 生产者负责选择将哪个记录分配给主题中的哪个分区。 可以以循环方式完成此操作，仅是为了平衡负载，也可以根据某些语义分区功能（例如基于记录中的某些键）进行此操作。

## Consumers 消费者
消费者使用消费者组名称(consumer group name)标记自己，并且发布到主题的每条记录都会使用`消费者组名`传递到每个订阅消费者组中的一个消费者实例。 消费者实例可以在单独的进程中或在单独的机器上。

如果所有消费者实例具有相同的消费者组,那么记录将有效地在使用者实例上进行负载平衡。 (如何实现的呢???)

如果所有消费者实例具有不同的消费者组，则每条记录将`广播`到所有消费者进程。(重复消费问题)
[consumer-groups.png]("/resource/consumer-groups.png")
上图是一个由两台服务器组成的Kafka群集，其中包含四个带有两个消费者组的分区（P0-P3）。 使用者组A有两个使用者实例，组B有四个。

但是，更常见的是，我们发现每个主题具有多个消费者组，每个消费者租只有一个“逻辑订阅户”。每个组均由许多消费者实例组成，以实现可伸缩性和容错能力。 这无非就是发布-订阅语义，其中订阅者是消费者的集群而不是单个进程。

Kafka中实现消费的方法是在消费者实例的日志中划分分区，这样每个实例在任何时候都是分区的“公平共享”的唯一使用者。Kafka协议动态处理了维护组成员身份的过程。如果新的实例加入组，它们将从组的其他成员那里接管一些分区;如果一个实例死亡，它的分区将分配给其余的实例。(重新分配导致的问题???)

Kafka仅提供分区中记录的总顺序，而不提供主题中不同分区之间的记录。对于大多数应用程序，按分区排序以及按键对数据进行分区的能力就足够了。 但是，如果您需要记录的总订单量，则可以通过只有一个分区的主题来实现，尽管这将意味着每个使用者组只有一个使用者进程。


## Multi-tenancy 一主多从
您可以将Kafka部署为多租户解决方案。 通过配置哪些主题可以产生或使用数据来启用多租户。 配额也有运营支持。 管理员可以对请求定义和实施配额，以控制客户端使用的代理资源。 有关更多信息，请参阅安全性文档。

## Guarantees 保证
在较高级别上，Kafka提供以下保证：

+ 生产者发送到特定主题分区的消息将按其发送顺序附加。也就是说，如果记录M1是由与记录M2相同的生产者发送的，并且首先发送M1，则M1的偏移量将小于M2，并在日志中更早出现。

+ 消费者实例按记录在日志中的存储顺序查看记录。

+ 对于复制因子为N的主题，我们最多可以容忍N-1个服务器故障，而不会丢失提交给日志的任何记录。

## Kafka as a Messaging System kafka作为消息系统
Kafka的流概念与传统的企业消息传递系统相比如何？

消息传递传统上有两种模式：`排队`和`发布-订阅`。

队列:一个消费者者池可以从一个服务器读取数据，并且每个记录都将被发送到其中的一个；

发布-订阅:记录中的消息广播给所有消费者。

排队的优势在于，它允许您将数据处理划分到多个使用者实例上，从而扩展处理量。 不幸的是，队列不是多用户的—一次进程读取了丢失的数据。
发布－订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法扩展处理。

Kafka中的消费者群体概念包括了这两种模式,与队列一样，消费者组允许您将处理划分到一组进程(使用者组的成员)上。与发布-订阅一样，Kafka允许您向多个用户组广播消息。

Kafka模型的优点是每个主题都有这两个属性，可以扩展处理，而且是多订阅者，没有必要选择其中一个。

Kafka也比传统的消息传递系统有更强的订购保证。

传统队列将记录按顺序保留在服务器上，如果多个消费者从队列中消费，则服务器将按记录的存储顺序分发记录。 但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给使用者的，因此它们可能会在不同的使用者上无序到达。 这实际上意味着在并行使用的情况下会丢失记录的顺序。 消息传递系统通常通过具有“专用消费者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。

Kafka在这方面做得更好,通过在主题内具有`并行性（即分区）`的概念，Kafka能够在用户进程池中提供`排序保证`和`负载均衡`。 这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。 通过这样做，我们确保使用者是该分区的唯一读取器，并按顺序使用数据。 由于存在许多分区，因此仍然可以平衡许多使用者实例上的负载。 但是请注意，`使用者组中的使用者实例不能超过分区`。

## Kafka as a Storage System Kafka作为一个存储系统
任何允许发布与使用解耦的消息的消息队列都有效地充当了动态消息的存储系统。Kafka的不同之处在于它本身就是一个非常好的存储系统。

写入Kafka的数据被写入磁盘并复制，以实现容错。Kafka允许生产者等待确认，这样直到完全复制并保证持久化(即使写入的服务器失败)，写入才算完成。

Kafka使用的磁盘结构具有良好的伸缩性，无论您在服务器上有50 KB还是50 TB的持久数据，Kafka都将执行相同的操作。

认真对待存储并允许客户端控制其读取位置的结果是，您可以将Kafka视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。

## Kafka for Stream Processing 用于流处理的Kafka

仅仅读取、写入和存储数据流是不够的，其目的是实现流的实时处理。

在Kafka中，流处理器是指从输入主题中获取连续的数据流，对这个输入执行一些处理，并产生连续的数据流输出到主题。

例如，一个零售应用程序可能接受销售和发货的输入流，并输出根据这些数据计算出的重新订购和价格调整流。

可以直接使用生产者和消费者api进行简单的处理。然而，对于更复杂的转换，Kafka提供了一个完全集成的Streams API。这允许构建进行重要处理的应用程序，这些处理可以从流计算聚合或将流连接在一起。

该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。

流API建立在Kafka提供的核心原语之上：它使用生产者和使用者API作为输入，使用Kafka进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。

## Putting the Pieces Together 整合
这种消息传递、存储和流处理的组合看起来很不寻常，但它对于Kafka作为一个流平台的角色是至关重要的。

像HDFS这样的分布式文件系统允许存储静态文件以进行批处理。 实际上，像这样的系统可以存储和处理过去的历史数据。

传统的企业消息传递系统允许处理将来的消息，这些消息将在您订阅后到达。 以这种方式构建的应用程序会在将来的数据到达时对其进行处理。

Kafka结合了这两项功能，对于将Kafka用作流应用程序平台和流数据管道平台而言，这种结合至关重要。

通过结合`存储`和`低延迟订阅`，流应用程序可以以相同的方式处理过去和将来的数据。 那是一个单一的应用程序可以处理历史记录中存储的数据，而不是在到达最后一条记录时结束，而是可以在将来的数据到达时继续进行处理。 这是流处理的通用概念，它包含批处理以及消息驱动的应用程序。