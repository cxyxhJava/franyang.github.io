---
layout:     post
title:      Kafka
subtitle:   kafka入门
date:       2019-02-25
author:     程序猿小哈
header-img: img/post-bg-os-metro.jpg
catalog: 	 true
tags:
    - 中间件
    - 消息队列
---

## kafka入门—分布式流平台（distributed streaming platform）

### 流平台
1. 流平台3个关键功能
 1.1 发布和订阅记录流，类似于消息队列或企业消息传递系统<br>
 1.2 以容错的持久方式存储记录流<br>
 1.3 记录发生时处理流<br>

2. Kafka通常用于两大类应用程序：
 + 建立实时流数据管道，以可靠地在系统或应用程序之间获取数据 
 + 构建实时流应用程序以转换或响应数据流

3. 一些概念
+ Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行
+ Kafka群集将记录流存储在称为主题(Topic)的类别中
+ 每个记录由一个键，一个值和一个时间戳组成.


4. kafka分为4个核心apis
 + Producer API 生产者api：向topic发布流数据<br>
 + Consumer API 消费者api：订阅topic，接收流数据<br>
 + Streams API ：流处理器，把生产者的输入流装换为消费者接收的输出流<br>
 + Connection API ： 用于建立连接，连接db等<br>


![kafka结构](/postImg/kafka/kafka02.jpg)

在Kafka中，客户端和服务器之间的通信是通过简单，高性能，与语言无关的`TCP协议`完成的。该协议已版本化，并与旧版本保持向后兼容性。我们为Kafka提供了Java客户端，但是客户端支持多种语言。

### 主体和日志(Topic And Log)


对于每个主题，Kafka集群都会维护一个分区日志，如下所示：
![topic](/postImg/kafka/kafka01.jpg)

每个`分区(partition)`都是`有序(ordered)`的，不可变的记录序列，这些记录连续地附加到结构化的提交日志中。每个分区中的记录都分配有一个`称为偏移(offset)的顺序ID号`，该ID唯一地标识分区中的每个记录。

Kafka集群使用`可配置的保留期限`持久保留所有已发布记录（无论是否已使用它们）

实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的`偏移量或位置`
offset由使用者控制 ,通常线性读取  但是位置由使用者控制 使用者也可以用需要的顺序使用


这些功能的组合意味着Kafka的消费者非常便宜-他们来来去去对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具来“尾部”任何主题的内容，而无需更改任何现有使用者所消耗的内容。 日志中的分区有多种用途。首先，它们允许日志扩展到超出单个服务器所能容纳的大小。每个单独的分区都必须适合托管它的服务器，但是一个主题可能有很多分区，因此它可以处理任意数量的数据。其次，它们充当并行性的单元-稍有更多。



### Distribution 分配

分区分为 领导者(leader)和追随者(follower)   leader负责读写  追随者被动复制数据. 当leader宕机 追随者变成leader(什么样的规则？？)


Kafka MirrorMaker 跨集群同步工具
MirrorMaker是Kafka附带的一个用于在Kafka集群之间制作镜像数据的工具


消费者可以 分组 Group

Multi-tenancy 多租户 

Guarantees 保证
+ 生产者发送到特定主题分区的消息将按其发送顺序附加。也就是说，如果记录M1是由与记录M2相同的生产者发送的，并且首先发送M1，则M1的偏移量将小于M2，并在日志中更早地出现。
+ 使用者实例按记录在日志中的存储顺序查看记录。
+ 对于副本数(replication)为N的主题(Topic)，我们最多可以容忍N-1个服务器故障，保证不会丢失提交给日志的任何记录。

？？ 如何实现的看 设计部分







### 概念词介绍
 + producer:消息和数据的生产者，向kafka的topic发布消息
 + consumer：消息的消费者，订阅数据（topic），并处理发布的消息
 + Consumer Group：逻辑概念，对应同一个topic，会广播给不同的group，一个group中，只有一个consumer可以消费该消息（避免负载均衡的时候重复消费？？）
 + Broker：物理概念，kafka集群中的每个kafka节点
 + Topic：逻辑概念，kafka消息的类别，对数据进行区分，隔离
 + Partition 分区：物理概念，kafka下数据存储的基本单元。一个Topic数据，会被分散存储到多个Partition，每一个Partition都是有序的
 + Replication 副本：同一个Partition可能会有多个Replica，多个Replica之间数据是一样的    
 + Reolication Leader:一个Partition的多个Replica需要一个Leader负责该Partition和Producer和Consumer交互
 + ReplicaManager：负责管理当前broker所在分区和副本的信息，处理kafkaController发起的一些请求，副本状态的切换。添加、读取信息等

### 详细介绍
#### 1.Partition（分区）：
 1. 每一个Topic被切分为多个Partitions
 2. 消费者数目少于或等于Partition的数据 （消费者去消费partition  那这个partition是怎么分的）
 3. Broker Group中的每一个Broker保存Topic的一个或多个Partitions （partition整体不会被多个broken保存，partition过大可以分割为多个额broken）
 4. Consumer Group中的仅有一个Consumer读取Topic的一个或多个Partition （一个topic只给一个cunsumer消费，tpoic中的Partition只给一个Consumer消费）
#### 2.Replication： 副本
 1. 默认为1，创建topic时单独创建
 2. 主从复制，主宕机，由ReplicaManager重新选举leader。
 3. 数据查询和写入，都是操作主副本。

#### 3.kafak安装
   1. docker安装
   2. 官网下载命令行安装
 
#### 4.kafka代码实例
   git地址后补
   
#### 5.kafka消息事务

数据传输的事务定义
 1. 最多一次：消息不会重新发送，最多传输一次，但也有可能一次不传
 2. 最少一次：消息不会被漏发送，最少被传输一次，但也有可能被重复传输
 3. 精确的一次（Exactly once）：不会漏传输也不会重复传输，每个消息都被传输一次且只有一次。

事务保证：
   1. 内部重试问题：Producer 幂等处理
   
   2. 多分区原子写入： offset topic  消息都有一个offerset 偏移量字段，当这个值传输入内置的offset topic时，标识消息被成功消费
   
   3. 避免僵尸实例：
   
     3.1 每个事务producer分配一个transactional.id，在进程重新启动时能够识别相同的Producer实例.   
     
     3.2 kafka增加了一个与transactional.id相关的epoch，存储每个transactional.id内部元数据.
     
     3.3 epoch被触发，任何具有相同的transactional.id和更旧的epoch的producer被视作僵尸，kafka会拒绝来着这些producer的后续事务性写入.

#### 零拷贝：
实现  JAVA Nio channel.transforTo()方法    linux sendfile系统调用
正常文件传输到网络的公共数据路径
 1. 操作系统磁盘到内核页缓存
 2. 应用程序吧数据从内核空间读入到用户空间缓存
 3. 应用程序吧数据从用户空间缓存写入到socket缓存
 4. 操作系统吧数据从socket缓存拷贝到网卡缓冲区，然后把数据从网络发出
   