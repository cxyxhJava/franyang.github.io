## kafka基础概念

### 概念词介绍
 + producer:消息和数据的生产者，向kafka的topic发布消息
 + consumer：消息的消费者，订阅数据（topic），并处理发布的消息
 + Consumer Group：逻辑概念，对应同一个topic，会广播给不同的group，一个group中，只有一个consumer可以消费该消息（避免负载均衡的时候重复消费？？）
 + Broker：物理概念，kafka集群中的每个kafka节点
 + Topic：逻辑概念，kafka消息的类别，对数据进行区分，隔离
 + Partition 分区：物理概念，kafka下数据存储的基本单元。一个Topic数据，会被分散存储到多个Partition，每一个Partition都是有序的
 + Replication 副本：同一个Partition可能会有多个Replica，多个Replica之间数据是一样的    
 + Reolication Leader:一个Partition的多个Replica需要一个Leader负责该Partition和Producer和Consumer交互
 + ReplicaManager：负责管理当前broker所在分区和副本的信息，处理kafkaController发起的一些请求，副本状态的切换。添加、读取信息等

### 详细介绍
#### 1.Partition（分区）：
 1. 每一个Topic被切分为多个Partitions
 2. 消费者数目少于或等于Partition的数据 （消费者去消费partition  那这个partition是怎么分的）
 3. Broker Group中的每一个Broker保存Topic的一个或多个Partitions （partition整体不会被多个broken保存，partition过大可以分割为多个额broken）
 4. Consumer Group中的仅有一个Consumer读取Topic的一个或多个Partition （一个topic只给一个cunsumer消费，tpoic中的Partition只给一个Consumer消费）
#### 2.Replication： 副本
 1. 默认为1，创建topic时单独创建
 2. 主从复制，主宕机，由ReplicaManager重新选举leader。
 3. 数据查询和写入，都是操作主副本。

#### 3.kafak安装
   1. docker安装
   2. 官网下载命令行安装
 
#### 4.kafka代码实例
   git地址后补
   
#### 5.kafka消息事务

数据传输的事务定义
 1. 最多一次：消息不会重新发送，最多传输一次，但也有可能一次不传
 2. 最少一次：消息不会被漏发送，最少被传输一次，但也有可能被重复传输
 3. 精确的一次（Exactly once）：不会漏传输也不会重复传输，每个消息都被传输一次且只有一次。

事务保证：
   1. 内部重试问题：Producer 幂等处理
   
   2. 多分区原子写入： offset topic  消息都有一个offerset 偏移量字段，当这个值传输入内置的offset topic时，标识消息被成功消费
   
   3. 避免僵尸实例：
   
     3.1 每个事务producer分配一个transactional.id，在进程重新启动时能够识别相同的Producer实例.   
     
     3.2 kafka增加了一个与transactional.id相关的epoch，存储每个transactional.id内部元数据.
     
     3.3 epoch被触发，任何具有相同的transactional.id和更旧的epoch的producer被视作僵尸，kafka会拒绝来着这些producer的后续事务性写入.

#### 零拷贝：
实现  JAVA Nio channel.transforTo()方法    linux sendfile系统调用
正常文件传输到网络的公共数据路径
 1. 操作系统磁盘到内核页缓存
 2. 应用程序吧数据从内核空间读入到用户空间缓存
 3. 应用程序吧数据从用户空间缓存写入到socket缓存
 4. 操作系统吧数据从socket缓存拷贝到网卡缓冲区，然后把数据从网络发出
   